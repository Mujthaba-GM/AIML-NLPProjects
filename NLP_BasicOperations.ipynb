{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3dFWc9OBXxGDnaYFR/gXl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mujthaba-GM/AIML-NLPProjects/blob/main/NLP_BasicOperations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qPI7YREE7KLY"
      },
      "outputs": [],
      "source": [
        "# import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing is fun! NLP makes machines understand human language.\"\n",
        "text_lower = text.lower()\n",
        "print(text_lower)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StEYnodA7WU4",
        "outputId": "49c75333-63f5-4809-81e0-63089939b315"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "natural language processing is fun! nlp makes machines understand human language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing stop words and punctuations\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "\n",
        "tokens_no_punct_stop = [\n",
        "    token.lemma_ for token in doc\n",
        "    if not token.is_punct and not token.is_stop\n",
        "]\n",
        "print(tokens_no_punct_stop)\n",
        "#word tokenizations\n",
        "word_tokens = [token.text for token in doc if not token.is_space]\n",
        "print(word_tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqTt3V9G7bEt",
        "outputId": "84e22ce3-53de-472d-c1c3-d5f0916b86f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'processing', 'fun', 'NLP', 'make', 'machine', 'understand', 'human', 'language']\n",
            "['Natural', 'Language', 'Processing', 'is', 'fun', '!', 'NLP', 'makes', 'machines', 'understand', 'human', 'language', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy # spacy ;inray im\n",
        "from collections import Counter\n",
        "\n",
        "# Load English tokenizer\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Your text\n",
        "text = \"I love this movie. It IT it it it it it it was beautifully made and well-acted. The movie was a masterpiece.\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Count only alphabetic words\n",
        "word_freq = Counter(token.text.lower() for token in doc if token.is_alpha)\n",
        "\n",
        "# Print word frequencies\n",
        "print(\"Word Frequencies:\")\n",
        "print(word_freq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "787jG_Lx7hhe",
        "outputId": "71cd51f4-5114-4429-a498-036fd7526c68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Frequencies:\n",
            "Counter({'it': 8, 'movie': 2, 'was': 2, 'i': 1, 'love': 1, 'this': 1, 'beautifully': 1, 'made': 1, 'and': 1, 'well': 1, 'acted': 1, 'the': 1, 'a': 1, 'masterpiece': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vector = Counter(token.lemma_ for token in doc if token.is_alpha and not token.is_stop)\n",
        "print(bow_vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUGRKA7i76D2",
        "outputId": "4109597a-734e-44a6-fe73-eae12713b3c4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'movie': 2, 'love': 1, 'beautifully': 1, 'act': 1, 'masterpiece': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_clean = [token.text for token in doc if token.is_alpha]\n",
        "bigrams = list(zip(tokens_clean, tokens_clean[1:]))\n",
        "print(bigrams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ_kr4tn8K59",
        "outputId": "b728edbe-14b5-4154-8f94-82b207e1e2b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'love'), ('love', 'this'), ('this', 'movie'), ('movie', 'It'), ('It', 'IT'), ('IT', 'it'), ('it', 'it'), ('it', 'it'), ('it', 'it'), ('it', 'it'), ('it', 'it'), ('it', 'was'), ('was', 'beautifully'), ('beautifully', 'made'), ('made', 'and'), ('and', 'well'), ('well', 'acted'), ('acted', 'The'), ('The', 'movie'), ('movie', 'was'), ('was', 'a'), ('a', 'masterpiece')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigrams = list(zip(tokens_clean, tokens_clean[1:], tokens_clean[2:]))\n",
        "print(trigrams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JTdj-4y-eHC",
        "outputId": "8d40dc3d-44dc-46ef-e837-b6ee00df5f06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'love', 'this'), ('love', 'this', 'movie'), ('this', 'movie', 'It'), ('movie', 'It', 'IT'), ('It', 'IT', 'it'), ('IT', 'it', 'it'), ('it', 'it', 'it'), ('it', 'it', 'it'), ('it', 'it', 'it'), ('it', 'it', 'it'), ('it', 'it', 'was'), ('it', 'was', 'beautifully'), ('was', 'beautifully', 'made'), ('beautifully', 'made', 'and'), ('made', 'and', 'well'), ('and', 'well', 'acted'), ('well', 'acted', 'The'), ('acted', 'The', 'movie'), ('The', 'movie', 'was'), ('movie', 'was', 'a'), ('was', 'a', 'masterpiece')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "print(pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFRsaZcX-rkr",
        "outputId": "779d7e39-4781-4a7f-e703-d083716ffb82"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRON'), ('love', 'VERB'), ('this', 'DET'), ('movie', 'NOUN'), ('.', 'PUNCT'), ('It', 'PRON'), ('IT', 'PRON'), ('it', 'PRON'), ('it', 'PRON'), ('it', 'PRON'), ('it', 'PRON'), ('it', 'PRON'), ('it', 'PRON'), ('was', 'AUX'), ('beautifully', 'ADV'), ('made', 'VERB'), ('and', 'CCONJ'), ('well', 'ADV'), ('-', 'PUNCT'), ('acted', 'VERB'), ('.', 'PUNCT'), ('The', 'DET'), ('movie', 'NOUN'), ('was', 'AUX'), ('a', 'DET'), ('masterpiece', 'NOUN'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKFgd4QM-uZm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}